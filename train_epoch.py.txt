import os
import numpy as np

def train_epoch(train_loader, model, loss_fn, optimizer, device):
    model.train()
    losses = []
    total_loss = 0
    for batch_idx, (data, target, _) in enumerate(train_loader):
        data = data.to(device)
        target = target.to(device)

        optimizer.zero_grad()
        output = model(data)
        target = target

        loss_outputs = loss_fn(output, target)

        losses.append(loss_outputs.item())
        total_loss += loss_outputs.item()
        if loss_outputs.requires_grad is True:
            loss_outputs.backward()
            optimizer.step()

        if batch_idx % 2 == 0:
            message = 'Train: [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(batch_idx * target.size(0), len(train_loader.dataset), 100. * batch_idx / len(train_loader), np.mean(losses))
            print(message)
            losses = []

    print('total loss {:.6f}'.format(total_loss/(batch_idx+1)))
